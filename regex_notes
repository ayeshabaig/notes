Regular Expressions

look like
\d{1,3}\.\d{1,3}.\d{1,3}\.\d{1,3}\
ipv4 address 1-3 # followed by a dot three times then a last 1-3 #s


examples of regex
globbing
ls *.txt
* - wildcard for any character
vim - uses regex for
^ - move to front of a line
$ - move to end of line

\d{1,3} - 1-3 numerical digits (0-9)
\. - matches literal . - has to be escaped bc . is a regex metachar

where do we use regex
programming - Perl, Java, PHP
text processing - awk, sed
applications - InDesign

how to wrtie regex - text editor, command line
how to test - 	RegExr (regexr.com)
  		Regex101 (regex101.com)
		Regex Pal (regexpal.com)
download apps exist, but are distro specific

regex engine
numerous libraries
numerous languages
work in similar basic way
	return leftmost token
	takes many of the same tokens
2 basic algorithms
nfa nondeterministic finite automaton
dfa deterministic finite automation

nfa - perl, python, vim, sed
  can 'go back' in the regex
dfa - cant go back - grep awk
ip regex above will work in nfa engines, but not dfa

Standards for regex
IEEE POSIX Standards
  BRE- Basic Regular Expressions
  ERE- Extended Regular Expressions
  SRE- Simple Regular Expressions- not used anymore
ERE builds off BRE
ERE adds repitition, alternation, changes the () and {}
DFA friendly
[:digit:] to match digit

PCRE- Perl Compatible Regular Expressions
used by Java, Python, .NET
Perl supports many Python implementations
NFA-minded

grep -P '\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}' ip
  runs PCRE grep wtih the ip address pattern on file named 'ip'
grep -E '\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}' ip
  runs ERE grep on ip which returns nothing bc \d is not supported
grep -E '[[:digit:]]{1,3}\.[[:digit:]]{1,3}\.[[:digit:]]{1,3}\.[[:digit:]]' ip
  returns the ips now


Literal Patterns
198\.51\.100\.23
198 - exact number given
\. - literal dot
curl some apache access logs
grep "198.51.100.23" access-logs
matches something but will also falsely match 198a51.100.23
so the dots need to be escaped
grep "198\.51\.100\.23"

Characters and Words
get processors file from github and put it into regexr.com

A-400                Enterprise                  Alpha Series                         $350.00
A-500                Enterprise                  Alpha Series                         $370.00
A-550                Enterprise                  Alpha Series                         $390.00
A-700                Enterprise                  Alpha Series                         $450.00
B-700                Enterprise                  Beta Series                          $500.00
B-800                Enterprise                  Beta Series                          $530.00
B-950                Enterprise                  Beta Series                          $600.00
D-440                Enterprise                  Delta Series                         $300.00
D-560                Enterprise                  Delta Series                         $350.00
D-780                Enterprise                  Delta Series                         $400.00
ET-770               Consumer                    Eta Series                           $300.00
ET-800               Consumer                    Eta Series                           $370.00
EP-300               Consumer                    Epsilon Series                       $100.00
EP-430a              Consumer                    Epsilon Series                       $150.00
EP-500               Consumer                    Epsilon Series                       $250.00
G-600                Enterprise                  Gamma Series                         $500.00
G-735                Enterprise                  Gamma Series                         $575.00
G-800                Enterprise                  Gamma Series                         $600.00
Gx-900               Enterprise                  Gamma Series                         $700.00
I-450q               Enterprise                  Gamma Series                         $400.00
I-500                Enterprise                  Gamma Series                         $450.00
Ix-900               Enterprise                  Gamma Series                         $750.00


/\w/g - matches any word, which includes numbers
/[A-D]\g - matches any uppercase letter between A and D
/[ABD]\g - matches only A, B, or D
/\W/g - matches any nonword
/[ABD]\W/g - matches an A, B, or D followed by a nonword
/[ABD]\W\w\w\w/g -
  [ABD] - match a character that is either A, B, or D (uppercase)
  \W - match a non-word character (NOT A-Z, a-z, 0-9)
  \w - match a word character (A-Z, a-z, 0-9); each \w is an individual token

Digits
\d - digit 0-9, each \d is an individual token
\D - not a digit
- - used outside of a range, the dash has no special meaning and can be used as a literal
/[ABD]-[6-9]\d\d/g
  [6-9] - match any number between 6 and 9

Whitespace
sed -i -r 's/\s\s+/\t/g' hostfile
sed -i -r -> invoke sed to process a file
's/\s\s+/\t/g' -> sed script to convert excess spaces to tabs
  /'s are namespace separators for the sed script: s/find/replace/g
  g - tells sed to work globally; i.e., continue after the first match

sample /etc/hosts file:
127.0.0.1	localhost

# demo environment

192.0.2.1	master
192.0.2.2       master2
192.0.2.32  db
192.0.2.100 		web1
192.0.2.110     web2

# internal

10.0.2.304  confluence
10.0.10.2	doc-test-servers
10.0.100.24     dev

\s - matches any whitespace - spaces, tabs, line breaks, carriage returns
\S - matches any non-whitespace
\t - tab
\n - newline
\r - carriage return
\v - vertical space
\s\s - any kind of whitespace, each \s is a single token
+ - repeat previous token one or more times
sed -i -r -> -i = edit and replace the file -r = use ERE

Unicode
not all regex engines support unicode
can match on the character directly
\u00e9 - unicode e with accent
can also match on unicode category
\b\pL+\b - match a string made of the letter Unicode category
regex101.com - supports unicode regex
unicode-table.com - has unicode table
pcre - doesn't support unicode
javascript - does support unicode
hostfile -> targeted file to run script against

^ and $
grep '^Graham' filename.txt - search for Graham at the beginning of the line
sudo grep 'nologin$' /etc/passwd - search /etc/passwd file for lines that end in 'nologin'
sed -i -r '/^\s*$/d' access-logs
sed -i -r -> invoke sed to edit a file in place using ERE
'/ -> namespace separator
^ -> match beginning of line
\s* -> match any ammount of whitespace (space, tab, carriage return, newline)
$ -> match end of line
/d -> delete matched pattern
access-logs -> targeted file to run script against

Boundaries - use \b to denote boundaries of words and nonwords
grep '\bVan\b' customer-data.txt
Opening boundary; any character before this cannot be a "word" character (matched with \w)
Closing boundary; any character after this cannot be a "word" character (matched with \w)
\B matches the opposite of \b
vim uses '\<Van\>' instead of '\bVan\b'

grep -Ei '\b(NJ|PA)\b' customer-data.txt
-E -> use ERE - extended regular expressions
-i -> case insensitive search
\b -> boundary
(NJ|PA) -> search for NJ or PA
\b -> boundary
customer-data.txt -> file to search against

Repitition
https?:\/\/(www\.)?([a-zA-Z0-9][a-zA-Z0-9\-]*)\.([a-zA-Z0-9]{2,63})\/?([a-zA-Z0-9][a-zA-Z0-9\-]*)?
? -> mark preceding token or subexpression as optional
+ -> repeat preceding token or subexpression 1 or more times
* -> repeat preceding token or subexpression 0 or more times
{2,63} -> repeat preceding token or subexpression 2-63 times
grep -Po 'https?:\/\/(www\.)?([a-zA-Z0-9][a-zA-Z0-9\-]*)\.([a-zA-Z0-9]{2,63})\/?([a-zA-Z0-9][a-zA-Z0-9\-]*)?' access-logs | sort -r | uniq -c
-P -> Perl regex
-o -> display only matched text not line containing matched text
regex to match websites
access-logs -> file to read from
sort -r -> sort in alphabetical order
uniq -c -> show unique matches with counts

Possessive Quantifiers
<.*>
. -> wildcard matches any single character
quantifiers are by nature greedy, matching as many characters as possible
<.*> -> matches all of `<i>regex</i>` not just the <i> tags
\*.*\* matches `*Regular expressions*, sometimes know as *regex*`
use a question mark to match in a non-greedy way
<.*?> matches <i> and <\i> not the whole expression
\*.*?\* matches `*Regular expressions` and `*regex*` not the whole expression
? -> repeat token as few times as possible when used after . or *

match an email address
[a-zA-Z0-9\!\#\$\%\&\'\*\+\-\/\=\?\^\_\`\{\|\}\~\.]+@[a-zA-Z0-9][a-zA-Z0-9\-]*\.[a-zA-Z0-9]{2,63}
grep -Po "[a-zA-Z0-9\!\#\$\%\&\'\*\+\-\/\=\?\^\_\`\{\|\}\~\.]+@[a-zA-Z0-9][a-zA-Z0-9\-]*\.[a-zA-Z0-9]{2,63}" customer-data.txt | sort > emails.txt
searches a list of customer data to grab email addresses, sort them and put them into a file called emails.txt

More character classes
match all states except DE
\b[^D\d\s][^E\d\s]\b
[] -> defined character class
^ -> signifies not to match the following tokens when contained in a class
D -> literal character
\d -> any digit 0-9
\s -> -> any whitespace character
for XML, .net, XPath a few others there is a way to subtract from a range

Backreferences
Match all header tags except H1
<([Hh][2-3]).*?>.+?<\/\1>
Match only HTML tags to strip out
<[^>]*>
grep -o -P "<([Hh][2-3]).*?>.+?<\/\1>" study-guide.html | sed 's/<[^>]*>//g' > toc.txt
find all of the lines that are not in h1 tags, strips out the tags, then outputs to a file

Named groups
Different implementations
Python
Named Group <(?P<tag>[Hh][2-3]).+?> -> named group is ?P<tag>
Reference <\/(?P=tag)>
.NET
Named Group <(?<tag>[Hh][2-3]).+?> -> ?<tag>
	    <(?'tag'[Hh][2-3]).+?> -> ?'tag'
Reference
<\/\k<tag>>
<\/\k'tag'>
PCRE
Named group <(?P<tag>[Hh][2-3]).+?> -> ?P<tag>
	    <(?<tag>[Hh][2-3]).+?>  -> ?<tag>
	    <(?'tag'[Hh][2-3]).+?>  -> ?'tag'
Reference <\/(?P=tag)>  <\/\g{tag}
	  <\/\k<tag>    <\/\k{tag}
		<\/\k'tag'>
example
grep -o -P "<(?'tag'[Hh][2-3]).+?>.*?<\/\k'tag'>" study-guide.html | sed 's/<[^>]*>//g'


Non-capturing groups
use parantheses to create groups that are easy to see without being counted against numerical backreferences
perl -lne '/(?:<[Hh][2-3].*?>)(.*?)(?:<\/[Hh][2-3]>)/ && print $1' study-guide.html
(?: - non-capturing group
< - Literals
[Hh] - range H or h
[2-3] - range: 2-3
. - wildcard; match any character
*? - repeat previous token zero or more times (non-greedy)
> - end of literals
$1 -> backreference to (.*?)

Learning Activity
Get page name and referrer from apache access logs
Put in format
Page: PAGE NAME
Referrrer: REFERRER
Access Logs look like:
198.51.100.8 - - [30/Oct/2018:00:46:55 ] "GET /linux HTTP/1.0" 200 2733 "http://linuxacademy.com/blog" "Mozilla/5.0 (iPad; CPU OS 6_0 like Mac OS X) AppleWebKit/536.26 (KHTML, like Gecko) Version/6.0 Mobile/10A5355d Safari/8536.25"

192.0.2.129 - - [30/Oct/2018:00:50:49 ] "GET /gcp HTTP/1.0" 200 2684 "http://www.linuxacademy.com" "Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 6.0)"

203.0.113.532 - - [30/Oct/2018:00:53:19 ] "GET /containers HTTP/1.0" 200 4293 "http://google.com" "Mozilla/5.0 (Windows; U; Windows NT 6.1; rv:2.2) Gecko/20110201"

203.0.113.23 - - [30/Oct/2018:00:54:13 ] "GET /containers HTTP/1.0" 200 4440 "http://linuxacademy.com/blog" "Mozilla/5.0 (iPad; CPU OS 6_0 like Mac OS X) AppleWebKit/536.26 (KHTML, like Gecko) Version/6.0 Mobile/10A5355d Safari/8536.25"

Start by grabbing this portion: "GET /containers HTTP/1.0" 200 4440 "http://linuxacademy.com/blog"
perl -lne '/GET (\/\w+?) HTTP\/1.0" 200 \d\d\d\d "https?:\/\/(?:www\.)?(\w[a-zA-Z0-9\-]*\w{2,63}(?:\/\w[a-zA-Z0-9\-]*)?)/ && print "Page: $1\nReferrer: $2\n"' access-logs > referrers.txt

Lookaheads
Match an extended zipcode, only capturing the first 5 digits
(\d{5})(?=-\d{4}) - this is a positive lookahead
(?=  ) -> match an expression in a group but do not capture it, works as a boundary
grep -P '(\d{5})(-\d{4})' customer-data.txt -> matches and returns entire ZIP+4 code
grep -P '(\d{5})(?=-\d{4})' customer-data.txt -> same line matches but only highlights first 5 digits

Negative lookaheads
Match any instance of linuxacademy.com not followed by "blog"
linuxacademy\.com(?!\/blog)
(?! ) -> ensure the grouped text does not follow the prior expression; works as a boundary
grep -P 'linuxacademy\.com' access-logs -> returns all logs with linuxacademy.com in them
grep -P 'linuxacademy\.com(?!\/blog)' access-logs -> returns all logs with linuxacademy.com but not linuxacademy.com/blog
grep -P "linuxacademy\.com(?!\/blog)" access-logs -> fails because bash does weird stuff to ! when using double-quotes

Lookbehinds
Positive lookbehinds
Find all metacharacters referenced in a study guide
(?<=<li><code>).+?(?=<\/code>)
(?<= ) -> matches an expression in that group, but does not capture it; works as a boundary
grep -Po '(?<=<li><code>).+?(?=<\/code)' study-guide.html ->
cannot use + or * based quantifiers in lookbehinds bc they can go on forever
Negative lookbehinds
Find all text within code tags that are not at the start of a line
(?<!<li><code>)(?<=<code>).+?(?=<\/code>)
(?<! ) -> ensures a group does not come before the following expression, works as a boundary
<li><code> -> literal matches

Take a Salt file, remove excess whitespace, use lookarounds to match all data between (---------)
and before 'changes:', output the data with grep -z to allow for multi-line matching
sed -i 's/^\s*//g' highstate -> -i = edit replace all spaces at beginning of line with nothing globally
grep -Pzo -> P - PCRE perl compatible regexes  z -> match across multiple lines  o -> only output matches
grep -Pzo '(?<=-{10})\n__id__:(?:\n|.)+?(?=changes:)' highstate > sls-report.txt
(?<=-{10}) -> lookbehind that finds 10 dashes in a row
\n__id__: -> literals
(?:\n|.)+? -> unnamed group - matches newline and anything 1 or more times, non-greedy
(?=changes:) -> lookahead for changes:

If Conditionals
Match only the ID and function lines of a log file
(ID|(Function)): (?(2)\w+?\.\w+|\w+)
(ID|(Function)) -> capturing group
(Function) -> second capturing group
ID, Function, and : are literals
| is or operator
(? ) -> if conditional group
(2) -> references the second captured group (Function);
    if the captured expression matches this capturing group,
    continue to match the following expression up until the vertical pipe
\w -> any word character
+? - repeat expression 1 or more times, non-greedy
\. - escaped literal
| - works as the "else" within the if conditional group; anything that does not match the (2) matches this
File contents to match from:
minion1:
----------
          ID: php_install
    Function: pkg.installed
        Name: php
      Result: True
     Comment: All specified packages are already installed
     Started: 16:19:04.217642
    Duration: 587.977 ms
     Changes:
----------
          ID: mod_mysql
    Function: pkg.installed
        Name: php-mysql
      Result: True
     Comment: All specified packages are already installed
     Started: 16:19:04.805807
    Duration: 14.708 ms
     Changes:
----------
          ID: mod_curl
    Function: pkg.installed
        Name: php-curl
      Result: True
     Comment: All specified packages are already installed
     Started: 16:19:04.820690
    Duration: 14.099 ms
     Changes:
----------

grep -Po '(ID|(Function)): (?(2)\w+?\.\w+|\w+)'

Named and Nested Conditionals
(ID|(?<fn>Function)|(?<dur>Duration)): (?(fn)\w+?\.\w+|(?(dur)\d+\.\d+ ms|\w+))
(ID|(?<fn>Function)|(?<dur>Duration)) -> capturing group
(?<fn>Function) -> named capturing group
(?<dur>Duration) -> named capturing group
ID, Function, Duration, : -> literals
(? -> if conditional
(fn) -> references the captured group called the "if" match; notice that only the name is needed
| works as the "else" with the if conditional group, anything that does not match the (fn) group matches this

Learning Activity
Return a list of Froms and Subjects from a file containing raw emails
To match From:
grep -Po 'From: \w+ <\w+@\w+\.\w{2,63}>' emaillist.mbox
From: - literal
\w+ - more than 0 word chars (name)
< - literal
\w+ - more than 0 word chars
@ - literal
To match Subject:
grep -Po 'Subject: .+' emaillist.mbox
To match both:
my answer: grep -Po '(From|(Subject)): (?(2).+|\w+ <\w+@\w+\.\w{2,63}>)' emaillist.mbox
correct answer: grep -Po '((From)|Subject): (?(2)\w+ <\w+@\w+\.\w{2,63}>|.+)' emaillist.mbox

Using a sed script to Generate Human-Readable Files
curl https://raw.githubusercontent.com/linuxacademy/content-mastering-regex/master/highstate -o hs.json
we want id, sls, and comments
heading for minion name
cp hs.json hs.test.json
vim minionreport.sed
---
#!/usr/bin/sed

s/^\s+// # remove whitespace at beginning of each line
1s/(.+?):/RUN REPORT: \1\n/ # 1s - runs substitute command on first line
			# (.+?): - capture group for up to :
			# \1 -> backreference to capture group
/-{10}/d # remove 10 dashes in a row
/^[a-z]+_\|/d # remove lines starting with lower letters then a _ and |
/p?changes:/d # remove lines with changes: or pchanges:
/^[a-z_]+:/ {
N # take this match and take the next line with it
s/\n\s+/ / # substitute newlines and following spaces with a single space
}
/^(__run_num__|duration|name|result|start_time|__state_ran__)/d # remove lines that start with those
s/__id__/ID/ # substitute __id__ with ID
s/__sls__/SLS/ # substitute __sls__ with SLS
s/comment: (.+)/Comment: \1\n/ # match comment and use capturing group, substitute with captured group and newline
---
sed -E -f minionreport.sed hs.json > minion1_2018-10-12

Learning Activity
Use a sed script to and the provided file mail-forwarding.txt, create a script that does the following:
Add the following to the top of the document:
  \documentclass{article}
  \usepackage{hyperref}
  \begin{document}
Encase the first line in a /title{NAME} tag
Convert all sections starting with Roman numerals to use \section{NAME}; dont keep numerals
Encase all lines starting with [root@red-hat ~]# in code blocks
  (\begin{verbatim} and \end{verbatim}; ~ can be alternate text
  There are some instances where two lines start with [root@red-hat ~]# immediately after one another,
  use sed's N functionality to write this portion of the script
Any lines beginning with four spaces or a tab should be contained in code blocks
Format any file names ending with .cf to use \texttt{TEXT} tags
Change anything encased in backticks to use \texttt{TEXT} tags
At the end of the document add \end{document}; this can be done by using $ a <APPENDED TEXT>
---
#!/usr/bin/sed

1s/(.+*)/\\documentclass{article}\n\\usepackage{hyperref}\n\\begin{document}\n\\title{\1}/
s/^[IVXLCDM]+\. (.+)/\\section{\1}/
/\[root@red-hat.+?]#/ {
    N
    s/(\[root@red-hat.+?\]#.+(\n\[root@red-hat.+)?)/\\begin{verbatim}\n\1\n\\end{verbatim}/
}
s/(\t|    )(.+)/\\begin{verbatim}\2\\end{verbatim}/
s/(\b\w+\.cf\b)/\\texttt{\1}/g
s/`(.+?)`/\\texttt{\1}/g
$ a \\\end{document}
---
sed -E -f latex.sed mail-forwarding.txt > mail-forwarding.txt

